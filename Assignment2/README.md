# Assignment 2: Pilot Usability Testing

Hanna Co | DH110 | Fall 2022

## Introduction

### About the Project
[UNEP](https://www.unep.org/) is the United Nations Environment Programme, and it sets the agenda for environmental actions and advocates for the environment. It informs the public on the UN efforts to combat environmental issues, as well as some ways that the public can get involved or help their cause.

After conducting a [heuristic evaluation](https://github.com/hannaco/DH110/blob/main/Assignment1/README.md) of the UNEP desktop website, I identified several usability concerns that should be addressed. When it came to user control and matching the system to the real world, there were minor changes that could've been made to eliminate confusion for the user. In terms of flexibility and efficiency of use, some aspects of the site were not intuitive or difficult to navigate. Finally, the site was densely packed with information and rescources for the user to learn about sustainability, which resulted in some elements of the site looking cluttered or not uniform with other elements of the site. Overall, while the site is usable and helpful, it can easily overwhelm the user

### The Purpose of Usability Testing

**Usability testing (UT)** is done to confirm or identify areas where the user may struggle with the site's functionality, or turn away from using it altogether. There are three components of usability: effectiveness, efficiency, and satisfaction. By observing users and giving them a set of tasks to complete, we can gather empirical data and observe areas for improvement, as well as what already works. We can get a real user's perspective, and and create sites and applications that are not only useful, but enojyable to use. Usability testing can help inform our design, which can save time and costs down the line. 

## Methodology
A pilot usability test (UT) was conducted in order to assess the materials, setting, and software used for usability testing. Due to limited formal testing space, the pilot UT was conducted in a minimalist portable test lab set up in a home setting. A laptop was used to run Zoom to record the user's facial expressions along with interactions with the website, and another laptop was used for the participant to fill out the [survey](https://docs.google.com/forms/d/e/1FAIpQLScKkK4JFiPDIyvAw645oKG36WBJO_igeXGJS6PRohB4tHtyTA/viewform?usp=sf_link). The moderator sat next to the participant.

The usability test and website of interest was first introduced to the participant, and the participant was given an informed consent form to sign. They were given pre-test questions regarding either their previous experience with the website, which might influence test performance, or their first impressions of the website. Keeping in mind the usability concerns mentioned before, the participant was then asked to perform 3 tasks:

1. Using the symptom checker, finding the disease/condition causing those symptoms, and finding what types of treatment are available for that disease/condition.
3. Finding the types of insurance Mayo Clinic accepts from patients.
4. Finding information about vitamin D supplements, including who may need to take vitamin D supplements, possible side effects, and daily recommended intake of vitamin D.

After completing the tasks, a set a post-test questions was given to assess the participant's quality of experience with the website, including their perceived ease of use and efficiency, their likeliness of doing each task, and their overall satisfaction with the website (either using System Usability Scale or Product Reaction Cards). Finally, demographic information about the participant was collected.

## Materials

The questionnaire consisted of the following components:
* Introduction script
* Informed consent
* Background questions
* Previous experience (if applicable)
* Pre-test questions
* Tasks
* Post-test questions
  * [System Usability Scale (SUS)](https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html)
  * [Product Reaction Cards](https://www.nngroup.com/articles/microsoft-desirability-toolkit/)
* Demographic questions

### Questionnaire Link
Link to the questionnaire (includes the moderator script and participant survey) [here](https://forms.gle/KmD63bt4S3oAK1mv6).

### Video Link
Link to the pilot UT [here](https://drive.google.com/file/d/1f98OxBLvMpZGYLmNlRhs_cf5W1ZxP-Ww/view?usp=sharing).

## Reflection

### What went well:
Overall, the usability testing went fairly smoothly, and the user was very vocal about any opinions and thoughts they had. Performing this pilot UT allowed me to practice not only creating an effective assesment of the usability of the site, but also how to conduct the test smoothly and professionally. It was difficult not to want to help the user, especially as I knew them personally, and it was difficult watching a friend struggle. Additionally, not every task was performed exactly the way I had planned, which it the part of the goal of usability testing, but I had to stop myself from interjecting or speaking up. Doing so would have impacted the results of this assessment.

Regarding the outcome of the test, the user confirmed a lot of the concerns I brought up during the heuristic evaluation. For example, they were also confused about how the offices were divided, as there was some overlap in the areas they covered. They also brought up how they didn't know what the graphic for the UN sustainability goals were, and thought it was just a colorful icon for aesthetics. Additionally, they agreed that some pages were a bit heavy on information, and that the difference between the two navigation bars were. The user affirmed that some parts of the site made it easy to use, such as error detection when inputting an email for subscribe to the newsletter.

During the usability test, some more usability issues came up, which would be helpful when designing my own site. For one, the search bar was not always present at the upper right corner, and only appeared on some pages, which confused both myself and the user. Additionally, the user was confused by the color scheme, as it seemed to change throughout the site -- it wasn't clear if the colors corresponded to anything, or was simply and aesthetic choice. Finally, the user searched something, but after reading an article, wanted to go back and look at more, and found that their search was cleared, which can become inconvenient when looking at multiple articles.

Conduting this usability test allowed me to observe how a potential user would interact with the site -- for one, the user rarely looks at the footer for crucial information; the user primarily only scrolled down to find contact information. Furthermore, it is important to not overwhelm them with terminology and text -- break it up, use images, and use language that most can understand. Finally, the user pointed out that some subheadings didn't make sense in the context of some pages, so it's important to either elaborate on headings I include, or make sure they are clearly relevant.

### What didn't go well:
There were a few minor issues when conducting the usability test. The biggest thing was that a lot of the tasks were simliar in nature, and the user became accustomed to beginning each task with a similar action. This was a shortcoming on my part, as it was a result of the test design and not the site. However, the site itself is largely informational and not very interactive, so I did struggle to come up with tasks for the user. I also did edit and rearrange my questionnaire several times, resulting in a couple typos, and a question that I had repeated on accident -- in the future, I should be more thorough with proofreading before conducting a usability test. Finally, there were a couple small issues regarding backgound noise or spotty internet connection, so it's important the try and find a quiet place in the future.
